{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9011940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\new_dacon\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e94029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] preprocessing\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] preprocessing\")\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':25,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "all_img_list = glob.glob('./train/*/*')\n",
    "\n",
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "# print(df['img_path'])\n",
    "# print(str(df['img_path'][0]).split('\\\\'))\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[1])\n",
    "\n",
    "\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ee5580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] datasets ready\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] datasets ready\")\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "\n",
    "        img_ar = np.fromfile(img_path, np.uint8)\n",
    "        image = cv2.imdecode(img_ar, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#         image = cv2.imread(img_path)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), \n",
    "                                        max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), \n",
    "                                        max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72228c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Model Define\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] Model Define\")\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b5(pretrained=True)\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc74858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Train\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] Train\")\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(\n",
    "            f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, best_score\n",
    "\n",
    "\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "\n",
    "    return _val_loss, _val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb586811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\efficientnet_v2_m-dc08266a.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 208M/208M [00:46<00:00, 4.70MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:48<00:00,  1.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.87358] Val Loss : [1.53496] Val Weighted F1 Score : [0.44924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:42<00:00,  1.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [1.51875] Val Loss : [1.17818] Val Weighted F1 Score : [0.60621]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [1.38813] Val Loss : [1.00640] Val Weighted F1 Score : [0.65445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [1.27859] Val Loss : [1.06946] Val Weighted F1 Score : [0.63923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [1.17517] Val Loss : [1.02161] Val Weighted F1 Score : [0.67439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [1.12474] Val Loss : [0.99056] Val Weighted F1 Score : [0.68927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [1.03898] Val Loss : [1.02411] Val Weighted F1 Score : [0.64647]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.95817] Val Loss : [1.06311] Val Weighted F1 Score : [0.69830]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.95593] Val Loss : [1.08152] Val Weighted F1 Score : [0.69136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:42<00:00,  1.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.92593] Val Loss : [1.05055] Val Weighted F1 Score : [0.70344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:45<00:00,  1.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.83776] Val Loss : [1.10742] Val Weighted F1 Score : [0.67051]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.84691] Val Loss : [1.04400] Val Weighted F1 Score : [0.71384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.77435] Val Loss : [1.08090] Val Weighted F1 Score : [0.69602]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.76853] Val Loss : [1.16198] Val Weighted F1 Score : [0.69551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:42<00:00,  1.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.77806] Val Loss : [1.06717] Val Weighted F1 Score : [0.72801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.73051] Val Loss : [1.21350] Val Weighted F1 Score : [0.69450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.69176] Val Loss : [1.09528] Val Weighted F1 Score : [0.71471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.69830] Val Loss : [1.12415] Val Weighted F1 Score : [0.73497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.71134] Val Loss : [1.08069] Val Weighted F1 Score : [0.71932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:42<00:00,  1.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.63374] Val Loss : [1.25346] Val Weighted F1 Score : [0.68930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:08<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.66716] Val Loss : [1.10810] Val Weighted F1 Score : [0.71852]\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.59663] Val Loss : [1.06709] Val Weighted F1 Score : [0.74590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.49411] Val Loss : [1.14435] Val Weighted F1 Score : [0.74053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:44<00:00,  1.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.46800] Val Loss : [1.13468] Val Weighted F1 Score : [0.75023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:43<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.45644] Val Loss : [1.15421] Val Weighted F1 Score : [0.74454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5,\n",
    "                                                       patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model, f1_score = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1b97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Inference\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] Inference\")\n",
    "\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de97364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "#             print(preds)\n",
    "            \n",
    "            preds = preds.argmax(1)\n",
    "            preds = preds.cpu().detach().numpy()\n",
    "            predictions += preds.tolist()\n",
    "#             preds += preds.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "#             probs = probs.cpu().detach().numpy()\n",
    "#             preds = probs > 0.5\n",
    "#             preds = preds.astype(int)\n",
    "#             predictions += preds.tolist()\n",
    "    prediction = le.inverse_transform(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849e1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:07<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a701a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  label\n",
       "0  TEST_000     18\n",
       "1  TEST_001     10\n",
       "2  TEST_002     18\n",
       "3  TEST_003      7\n",
       "4  TEST_004     18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[*] Submission\")\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f7ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.loc[submit['label'] == 0, 'label'] = '가구수정'\n",
    "submit.loc[submit['label'] == 1, 'label'] = '걸레받이수정'\n",
    "submit.loc[submit['label'] == 2, 'label'] = '곰팡이'\n",
    "submit.loc[submit['label'] == 3, 'label'] = '꼬임'\n",
    "submit.loc[submit['label'] == 4, 'label'] = '녹오염'\n",
    "submit.loc[submit['label'] == 5, 'label'] = '들뜸'\n",
    "submit.loc[submit['label'] == 6, 'label'] = '면불량'\n",
    "submit.loc[submit['label'] == 7, 'label'] = '몰딩수정'\n",
    "submit.loc[submit['label'] == 8, 'label'] = '반점'\n",
    "submit.loc[submit['label'] == 9, 'label'] = '석고수정'\n",
    "submit.loc[submit['label'] == 10, 'label'] = '오염'\n",
    "submit.loc[submit['label'] == 11, 'label'] = '오타공'\n",
    "submit.loc[submit['label'] == 12, 'label'] = '울음'\n",
    "submit.loc[submit['label'] == 13, 'label'] = '이음부불량'\n",
    "submit.loc[submit['label'] == 14, 'label'] = '창틀,문틀수정'\n",
    "submit.loc[submit['label'] == 15, 'label'] = '터짐'\n",
    "submit.loc[submit['label'] == 16, 'label'] = '틈새과다'\n",
    "submit.loc[submit['label'] == 17, 'label'] = '피스'\n",
    "submit.loc[submit['label'] == 18, 'label'] = '훼손'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d0af7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>오염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>몰딩수정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>훼손</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id label\n",
       "0  TEST_000    훼손\n",
       "1  TEST_001    오염\n",
       "2  TEST_002    훼손\n",
       "3  TEST_003  몰딩수정\n",
       "4  TEST_004    훼손"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f762da",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./results/f1_'+str(f1_score) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_dacon_",
   "language": "python",
   "name": "new_dacon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
